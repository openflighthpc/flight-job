#!/bin/bash -l
#==============================================================================
# Copyright (C) 2021 Alces Flight Ltd.
#
# This work is licensed under a Creative Commons Attribution-ShareAlike
# 4.0 International License.
#
# See http://creativecommons.org/licenses/by-sa/4.0/ for details.
#==============================================================================
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#                        SLURM SUBMISSION SCRIPT
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> OPERATIONAL DIRECTIVES - change these as required
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

#=====================
#  Working directory
#---------------------
# The following directive overrides the jobs working directory to the
# specified location.
#
# Alternatively, adding an additional comment marker will disable the
# override. Your job will then be executed in the directory from which
# it was submitted.
#
#SBATCH -D <%= File.expand_path("~") %>

#=========================
#  Environment variables
#-------------------------
# When set to "ALL", this setting exports all variables present when
# the job is submitted.  Set to "NONE" to disable environment variable
# propagation, or a comma-separated list to be more selective.
#
#SBATCH --export=ALL

#================
#  Output files
#----------------
# Set an output file for messages generated by your job script
#
# Specify a path to a file to contain the output from the standard
# output stream of your job script. If you omit `-e` below,
# standard error will also be written to this file.
#
#SBATCH -o starccm-<%=
  questions.job_type.answer.to_s
%>-%j.out.txt

#============
#  Job name
#------------
# Set the name of your job - this will be shown in the process
# queue.
#
#SBATCH -J starccm-<%=
  File.basename(questions.input_filename.answer.to_s, '.sim')
%>-<%=
  questions.job_type.answer.to_s
%>

#=======================
#  Email notifications
#-----------------------
# Set the destination email address for notifications.  If not set,
# will send mail to the submitting user on the submission host.
#
#SBATCH --mail-user=<%= questions.notification_address.answer %>

# Set the conditions under which you wish to be notified.
# Valid options are: NONE, BEGIN, END, FAIL, REQUEUE, ALL (equivalent
# to BEGIN, END, FAIL, REQUEUE, and STAGE_OUT), STAGE_OUT (burst
# buffer stage out and teardown completed), TIME_LIMIT, TIME_LIMIT_90
# (reached 90 percent of time limit), TIME_LIMIT_80 (reached 80
# percent of time limit), TIME_LIMIT_50 (reached 50 percent of time
# limit) and ARRAY_TASKS (send emails for each array task). Multiple
# type values may be specified in a comma separated list.
# If not specified, will send mail if the job is aborted.
#
#SBATCH --mail-type ALL

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> RESOURCE REQUEST DIRECTIVES - always set these
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

#===================
#  Maximum runtime
#-------------------
# Expected RUNTIME
#
# Enter the expected runtime for your job.  Specification of a
# shorter runtime will cause the scheduler to be more likely to
# schedule your job sooner, but note that your job **will be
# terminated if it is still executing after the time specified**.
#
# A time limit of zero requests that no time limit be imposed.
# Format: one of "minutes", "minutes:seconds",
# "hours:minutes:seconds", "days-hours", "days-hours:minutes" and
# "days-hours:minutes:seconds". e.g. `3-0` for 3 days.
#SBATCH --time=0

#================
#  Memory limit
#----------------
# Expected HARD MEMORY LIMIT
#
# Enter the expected memory usage of your job.  Specification of a
# smaller memory requirement will cause the scheduler to be more
# likely to schedule your job sooner, but note that your job **may
# be terminated if it exceeds the specified allocation**.
#
# Note that this setting is specified in megabytes.
# e.g. specify `1024` for 1 gigabyte.
#
#SBATCH --mem=0

#==========================
#  Processing requirements
#--------------------------
<% if questions.job_type.answer.to_s == "mesh" -%>
#SBATCH --ntasks=<%= questions.mesh_cores.answer %>
<% else -%>
#SBATCH --ntasks=<%= questions.solve_cores.answer %>
<% end -%>

#=====================
#  Specify partition
#---------------------
<% if questions.job_type.answer.to_s == "mesh" -%>
#SBATCH -p pp
<% else -%>
#SBATCH -p thermal
<% end -%>

<% if questions.await_job.answer.to_s != "" -%>
#================
#  Dependencies
#----------------
# Wait for the completion of job <%= questions.await_job.answer %> prior to starting.
#SBATCH --dependency=afterok:<%= questions.await_job.answer %>
<% end -%>

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> SET TASK ENVIRONMENT VARIABLES
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
# If necessary, set up further environment variables that are not
# specific to your workload here.
#
# Several standard variables, such as SLURM_JOB_ID, SLURM_JOB_NAME and
# SLURM_NTASKS, are made available by the scheduler.

#POD_KEY="TBC"
POD_KEY="s4gjoHYHDucNWISVRY+50Q"

#=====================
#  Results directory
#---------------------
# By convention, job's submitted with `flight-job` are expected to save their
# results to RESULTS_DIR.  `flight-job` provides easy access to any files
# saved there.
#
# If RESULTS_DIR is modified, `flight-job` will be unable to track the job's
# results.
#
# WARNING: The script must not change directory prior to this line.
RESULTS_DIR="$(pwd)/${SLURM_JOB_NAME}-outputs/$SLURM_JOB_ID"

#===========================
#  Create results directory
#---------------------------
mkdir -p "$RESULTS_DIR"

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> YOUR WORKLOAD
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

INPUT_BASE="/mnt/thermal/starccm/jobs"
<%# #INPUT_BASE="/mnt/cstor01/projects/TestCases/ccm-for-alces" -%>
<%# #INPUT_BASE="/users/alces-cluster/starccm" -%>
INPUT_FILE="<%= questions.input_filename.answer %>"
INPUT_DIR="<%= questions.input_dir.answer %>"
INPUT_DIR="${INPUT_DIR:-$(basename ${INPUT_FILE} .sim)}"

MACROS="<%= questions.macros.answer %>"
STARCCM_VERSION="<%= questions.starccm_version.answer %>"

INPUT_PATH="${INPUT_BASE}/${INPUT_DIR}"
if [ ! -e ${INPUT_PATH}/${INPUT_FILE} ]; then
    echo "Unable to locate input file: ${INPUT_PATH}/${INPUT_FILE}"
    if [ -d ${INPUT_PATH} ]; then
	cp $HOME/starccm-<%= questions.job_type.answer.to_s %>-${SLURM_JOB_ID}.out.txt ${INPUT_PATH}
    fi
    exit 1
fi

WD="/mnt/scratch/thermal/starccm/jobs/job-$SLURM_JOB_ID"
mkdir -p "$WD"

echo "Copying input from ${INPUT_PATH}..."
shopt -s nullglob
cp -Rv ${INPUT_PATH}/${INPUT_FILE} ${INPUT_PATH}/*.java ${WD}
shopt -u nullglob

cd $WD

scontrol show hostname $SLURM_NODELIST | tr 'ec' 'ic'> machinefile.${SLURM_JOB_ID}

STARCCMBIN="/opt/apps/thermal/siemens/${STARCCM_VERSION}/STAR-CCM+${STARCCM_VERSION}/star/bin"
<% if questions.job_type.answer.to_s == "mesh" -%>

export MPI_FLUSH_CACHE=5
<% end %>
${STARCCMBIN}/starccm+ \
    -fabricverbose \
<% if questions.job_type.answer.to_s == "solve" -%>
    -fabric IBV -cpubind v \
<% else -%>
    -cpubind v \
<% end -%>
<% if questions.macros.answer.to_s != "" -%>
    -batch ${MACROS} \
<% end -%>
    -power \
    -podkey ${POD_KEY} \
    -licpath 1999@flex.cd-adapco.com \
    -np $SLURM_NTASKS -rsh ssh -machinefile machinefile.${SLURM_JOB_ID} \
    ${INPUT_FILE}

cp $HOME/starccm-<%= questions.job_type.answer.to_s %>-${SLURM_JOB_ID}.out.txt ${INPUT_PATH}

# Copy output files back to storage
<% if questions.job_type.answer.to_s == "solve" -%>
shopt -s nullglob
for a in "${WD}/$(basename "${INPUT_FILE}" .sim | cut -f1 -d'@')"@[0-9]*.sim; do
    S="$(basename "$a")"
    T="${S}"
    if [ -e "${INPUT_PATH}/${S}" ]; then
	T="$(basename "$a" .sim).${SLURM_JOB_ID}.sim"
    fi
    cp -v $a "${INPUT_PATH}/${T}"
done
shopt -u nullglob
<% else -%>
S="$(basename "${INPUT_FILE}" .sim)@meshed.sim"
T="${S}"
if [ -e "$S" ]; then
    if [ -e "${INPUT_PATH}/${S}" ]; then
	T="$(basename "${INPUT_FILE}" .sim)@meshed.${SLURM_JOB_ID}.sim"
    fi
    cp -v "${WD}/${S}" "${INPUT_PATH}/${T}"
fi
<% end -%>

cd $HOME
rm -rf "${WD}"
