#!/bin/bash -l
#==============================================================================
# Copyright (C) 2020 Alces Flight Ltd.
#
# This work is licensed under a Creative Commons Attribution-ShareAlike
# 4.0 International License.
#
# See http://creativecommons.org/licenses/by-sa/4.0/ for details.
#==============================================================================
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#                        SLURM SUBMISSION SCRIPT
#                       AVERAGE QUEUE TIME: Short
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> OPERATIONAL DIRECTIVES - change these as required
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

#=====================
#  Working directory
#---------------------
# The following directive overrides the jobs working directory to the
# specified location.
#
# Alternatively, adding an additional comment marker will disable the
# override. Your job will then be executed in the directory from which
# it was submitted.
#
#SBATCH -D <%= File.expand_path questions.working_dir.answer %>

#=========================
#  Environment variables
#-------------------------
# When set to "ALL", this setting exports all variables present when
# the job is submitted.  Set to "NONE" to disable environment variable
# propagation, or a comma-separated list to be more selective.
#
#SBATCH --export=ALL

#================
#  Output files
#----------------
# Set an output file for messages generated by your job script
#
# Specify a path to a file to contain the output from the standard
# output stream of your job script. If you omit `-e` below,
# standard error will also be written to this file.
#
#SBATCH -o <%= questions.stdout_file.answer %>

# Set an output file for STDERR
#
# Specify a path to a file to contain the output from the standard
# error stream of your job script.
#
# This is not required if you want to merge both output streams into
# the file specified above.
#
<% if questions.merge_stderr_with_stdout.answer.to_s == 'yes' -%>
##SBATCH -e <%= questions.stderr_file.default %>
<% else -%>
#SBATCH -e <%= questions.stderr_file.answer %>
<% end -%>

#============
#  Job name
#------------
# Set the name of your job - this will be shown in the process
# queue.
#
#SBATCH -J <%= questions.job_name.answer %>

#=======================
#  Email notifications
#-----------------------
# Set the destination email address for notifications.  If not set,
# will send mail to the submitting user on the submission host.
#
<% if questions.notification_wanted.answer == 'yes' -%>
#SBATCH --mail-user=<%= questions.notification_address.answer %>
<% else -%>
##SBATCH --mail-user=<%= questions.notification_address.default %>
<% end -%>

# Set the conditions under which you wish to be notified.
# Valid options are: NONE, BEGIN, END, FAIL, REQUEUE, ALL (equivalent
# to BEGIN, END, FAIL, REQUEUE, and STAGE_OUT), STAGE_OUT (burst
# buffer stage out and teardown completed), TIME_LIMIT, TIME_LIMIT_90
# (reached 90 percent of time limit), TIME_LIMIT_80 (reached 80
# percent of time limit), TIME_LIMIT_50 (reached 50 percent of time
# limit) and ARRAY_TASKS (send emails for each array task). Multiple
# type values may be specified in a comma separated list.
# If not specified, will send mail if the job is aborted.
#
<% if questions.notification_wanted.answer == 'yes' -%>
#SBATCH --mail-type <%= questions.notification_events.answer.join(',') %>
<% else -%>
##SBATCH --mail-type <%= questions.notification_events.default.join(',') %>
<% end -%>

#============
#  Deadline
#------------
# Set a deadline by which your job must complete.
#
# If Slurm is not able to schedule your job so that it will complete prior to
# deadline, it will either fail to submit, or if already submitted, will be
# cancelled.  In order for this to work correctly, the maximum runtime
# directive must be set.
#
# Set the deadline to 3 hours from now.
##SBATCH --deadline=now+3:0:0
#
# Set the deadline to 5pm.  Either 5pm today, or 5pm tomorrow if it is later
# than 5pm.
##SBATCH --deadline=17:00:00

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> RESOURCE REQUEST DIRECTIVES - always set these
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

#===================
#  Maximum runtime
#-------------------
# Expected RUNTIME
#
# Enter the expected runtime for your job.  Specification of a
# shorter runtime will cause the scheduler to be more likely to
# schedule your job sooner, but note that your job **will be
# terminated if it is still executing after the time specified**.
#
# A time limit of zero requests that no time limit be imposed.
# Format: one of "minutes", "minutes:seconds",
# "hours:minutes:seconds", "days-hours", "days-hours:minutes" and
# "days-hours:minutes:seconds". e.g. `3-0` for 3 days.
#SBATCH --time=<%= questions.max_runtime.answer %>

#================
#  Memory limit
#----------------
# Expected HARD MEMORY LIMIT
#
# Enter the expected memory usage of your job.  Specification of a
# smaller memory requirement will cause the scheduler to be more
# likely to schedule your job sooner, but note that your job **may
# be terminated if it exceeds the specified allocation**.
#
# Note that this setting is specified in megabytes.
# e.g. specify `1024` for 1 gigabyte.
#
#SBATCH --mem=<%= questions.memory_limit.answer %>

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> SET TASK ENVIRONMENT VARIABLES
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
# If necessary, set up further environment variables that are not
# specific to your workload here.
#
# Several standard variables, such as SLURM_JOB_ID, SLURM_JOB_NAME and
# SLURM_NTASKS, are made available by the scheduler.

#============================
#  Results / Metadata directory
#----------------------------
# By convention, job's submitted with `flight-job` are expected to save their
# results to RESULTS_DIR.  `flight-job` provides easy access to any files
# saved there.
#
# If RESULTS_DIR is modified, `flight-job` will be unable to track the job's
# results.
#
# The CONTROLS_DIR is used internally to track various flight-job data files.
# This is primarily used to store the VNC settings for the interactive
# sesison.
#
# WARNING: The script must not change directory prior to this line.
RESULTS_DIR="$(pwd)/${SLURM_JOB_NAME}-outputs/$SLURM_JOB_ID"
CONTROLS_DIR="${CONTROLS_DIR:-$RESULTS_DIR}"
FLIGHT_SESSION_ID_PATH="${CONTROLS_DIR}"/flight-desktop-id
FLIGHT_SESSION_STATUS_PATH="${CONTROLS_DIR}"/flight-desktop-status
SESSION_OUTPUT="${RESULTS_DIR}/session.output"
mkdir -p "$CONTROLS_DIR"
mkdir -p "$RESULTS_DIR"

#=========================
#  Session orchestration
#-------------------------
# Functions used to orchestrate the creation of your interactive session with
# Flight Desktop.
create_session_script() {
    SESSION_SCRIPT=$( mktemp --tmpdir session-script.XXXXXX.sh )
    echo "Creating session script ${SESSION_SCRIPT}"
    export SESSION_SCRIPT
    cat > ${SESSION_SCRIPT}
    chmod +x ${SESSION_SCRIPT}
}

session_run() {
    session_start
    session_await
}

session_start() {
    if [ "${SESSION_SCRIPT}" == "" ] ; then
        echo "Session script not created. Aborting." >&2
        exit 1
    fi
    echo "Starting session..."
    ${flight_ROOT:-/opt/flight}/bin/flight desktop \
        start \
        --script ${SESSION_SCRIPT} \
        | tee >( grep '^Identity' | cut -f2 > "${FLIGHT_SESSION_ID_PATH}" )

    SESSION_STARTED=$?
    echo ${SESSION_STARTED} > "$FLIGHT_SESSION_STATUS_PATH"
}

session_is_active() {
    local state
    state=$(
        ${flight_ROOT:-/opt/flight}/bin/flight desktop \
            show "${SESSION_ID}" 2>/dev/null \
            | grep '^State' \
            | cut -d $'\t' -f 2
    )
    [ "${state}" == "Active" ]
}

session_await() {
    if [ ${SESSION_STARTED} -ne 0 ] ; then
        echo "Session failed to start. Aborting." >&2
        exit 1
    fi
    SESSION_ID=$(cat "${FLIGHT_SESSION_ID_PATH}")
    SESSION_ID=${SESSION_ID##[[:space:]]}
    SESSION_ID=${SESSION_ID%%[[:space:]]}
    if [ "${SESSION_ID}" == "" ] ; then
        echo "Unable to determine session ID. Aborting." >&2
        exit 1
    fi
    echo "Session ID is ${SESSION_ID}" 
    echo "Waiting for session to end..." 
    while session_is_active ; do
        sleep 60
    done
    echo "Session is no longer running."
}

# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
#  >>>> YOUR WORKLOAD
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

#===========================
#  Results directory
#---------------------------
# By convention, job's submitted with `flight-job` are expected to save their
# results to RESULTS_DIR.  `flight-job` provides easy access to any files
# saved there.
#
# Your job can save its results anywhere you want, but if the results are
# saved outside of RESULTS_DIR (or if RESULTS_DIR is modified), 'flight-job'
# will be unable to help you access your results.
#
# RESULTS_DIR has already been set to "${WORKING_DIR}/${SLURM_JOB_NAME}-outputs/$SLURM_JOB_ID".
echo "Your results will be stored in: $RESULTS_DIR"

create_session_script <<SESSION
#!/bin/bash

#===============================
#  Activate Flight Environment
#-------------------------------
source "${flight_ROOT:-/opt/flight}"/etc/setup.sh > "${SESSION_OUTPUT}" 2>&1

#==============================
#  Activate Package Ecosystem
#------------------------------
{
# e.g.:
# flight env activate modules
# module load apps/R

flight env activate gridware
module load apps/R
} >> "${SESSION_OUTPUT}" 2>&1

#===============================
#  Application launch commands
#-------------------------------
# Customize this section to suit your needs.

echo "Executing job commands, current working directory is $(pwd)" >> "${SESSION_OUTPUT}" 2>&1

# REPLACE THE FOLLOWING WITH YOUR APPLICATION COMMANDS

# Additional command-line options (R -h for a list).
R_OPTIONS=""
R "$R_OPTIONS"
SESSION

session_run
